{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4h-tX9MO6nk"
      },
      "source": [
        "#### Sequential\n",
        "- Simple and concise for linear architecture\n",
        "- Limited to layer stacking.\n",
        "- Not good with skip connections, custom models.\n",
        "#### Functional API\n",
        "- Flexible but requires more code.\n",
        "- Allows any custom computation logic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWmuKu33O6ny"
      },
      "source": [
        "# 1.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NILPBDghO6n0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXLESmAWO6n4",
        "outputId": "a5209bc6-fcc9-4763-b3bc-37d6e6dbd172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=32, out_features=5, bias=True)\n",
            ")\n",
            "tensor([[ 2.8063e-01, -7.9068e-01, -4.8522e-01,  2.2687e+00, -7.6368e-02,\n",
            "         -3.3985e-02, -7.2436e-01,  9.4620e-01, -1.0664e+00,  9.4917e-01,\n",
            "          8.5967e-01, -2.0032e-01,  4.4371e-01, -6.4870e-01, -2.4266e-01,\n",
            "          1.1356e+00,  2.0589e-01,  2.7088e-01, -6.2396e-01,  1.1146e+00],\n",
            "        [ 1.4537e-01,  3.7606e-01,  5.5491e-01,  8.5518e-01, -1.2878e+00,\n",
            "         -1.0719e-02, -2.1461e+00,  8.7564e-01,  5.3515e-01,  1.0100e+00,\n",
            "          5.3628e-01,  5.7761e-01,  1.5451e+00, -3.4532e-01, -1.3994e+00,\n",
            "          2.9451e-02, -9.9007e-01, -1.5339e+00,  5.4602e-01, -5.4578e-01],\n",
            "        [-7.6722e-01,  1.2141e+00,  7.4831e-01,  9.0141e-01,  1.8835e-01,\n",
            "         -2.2946e-01,  3.5685e-01, -5.3332e-01,  8.4887e-02,  4.5192e-01,\n",
            "         -9.6046e-01, -1.1967e+00,  2.9536e-01, -1.9863e+00, -1.6049e+00,\n",
            "         -1.5336e+00,  1.0629e+00, -1.2466e+00,  8.6803e-01,  1.4356e-01],\n",
            "        [-3.5949e-01,  6.1150e-01, -1.1258e-01, -1.5367e-01, -1.1208e+00,\n",
            "          2.1663e-01, -6.5958e-01, -1.0065e+00,  1.4865e-01,  1.6169e+00,\n",
            "         -6.1103e-01,  1.3126e+00,  1.2374e+00, -7.0665e-01,  8.7598e-01,\n",
            "          1.3812e+00,  5.3162e-01,  1.3190e+00,  1.1554e+00, -5.8914e-01],\n",
            "        [-1.9129e+00,  1.7847e-01,  5.0647e-01, -1.3205e+00,  1.4704e+00,\n",
            "         -3.4103e-01,  5.9881e-01,  9.7800e-01, -1.4527e+00, -5.8117e-01,\n",
            "         -9.8084e-02, -1.3326e+00, -7.9190e-01, -1.5241e+00, -4.5135e-01,\n",
            "          1.2027e+00, -2.4396e+00,  3.4533e-01, -7.9089e-04,  2.1274e-02],\n",
            "        [-4.1165e-01, -8.5646e-01, -2.1906e+00, -1.4140e+00, -8.8864e-02,\n",
            "         -4.1517e-01, -1.4423e+00,  4.7710e-01, -8.5900e-01, -4.0636e-01,\n",
            "          1.6319e+00, -1.1385e+00,  5.6588e-01, -8.2110e-01,  6.6619e-01,\n",
            "         -4.7451e-01,  8.2068e-01,  1.2692e+00,  1.7063e+00, -1.9729e-01],\n",
            "        [ 6.0288e-01, -2.1154e+00,  2.1854e-01,  5.5266e-02,  1.3287e-01,\n",
            "          2.5284e-01, -2.8941e-01,  1.9833e-01, -3.8179e-01,  3.8384e-01,\n",
            "         -6.5925e-01,  4.8227e-01, -1.4667e+00,  1.6425e+00,  9.1118e-01,\n",
            "         -1.0406e+00, -2.1537e+00,  4.2119e-01,  9.5762e-01, -1.4360e+00],\n",
            "        [ 2.7737e-01,  8.8270e-01, -2.3415e-01,  1.2043e+00,  3.3890e-01,\n",
            "         -9.2781e-01, -1.0801e+00,  9.6606e-01,  1.4569e+00, -2.3095e-01,\n",
            "          1.1106e+00,  1.3749e+00, -6.1386e-02, -1.8850e-01, -7.6746e-01,\n",
            "         -9.5567e-01,  7.7978e-01, -1.2640e+00,  1.6743e+00,  1.1600e+00],\n",
            "        [-3.5325e-03, -3.9856e-01,  2.1350e-01, -8.7037e-01, -1.0647e+00,\n",
            "          2.7226e-01,  1.7353e-01, -5.7080e-01,  3.6374e-01, -8.4339e-01,\n",
            "          1.5519e+00, -3.5991e-01, -1.1725e+00, -2.1605e+00,  3.8718e-01,\n",
            "         -1.4043e+00, -6.5737e-01, -2.2236e+00, -5.0334e-03, -2.8434e-01],\n",
            "        [-5.8133e-01, -9.4048e-01, -7.1085e-01,  7.4783e-01, -1.1920e+00,\n",
            "          2.2296e+00,  1.7319e+00, -3.1882e+00,  5.4832e-01, -1.0649e+00,\n",
            "         -6.6233e-01,  6.7733e-01,  1.7117e+00,  1.1842e+00, -6.8451e-01,\n",
            "         -6.1007e-01, -1.7369e+00,  5.0194e-01,  2.3012e-02,  1.9514e-01]])\n",
            "========================================\n",
            "tensor([[-0.0698,  0.0520,  0.0370,  0.2849,  0.0464],\n",
            "        [-0.0534, -0.0531, -0.0617,  0.2774,  0.0118],\n",
            "        [-0.0753, -0.0864, -0.0388,  0.2161,  0.0045],\n",
            "        [-0.0726,  0.0042,  0.0215,  0.2393, -0.0336],\n",
            "        [-0.0756, -0.0400, -0.0938,  0.0629,  0.0292],\n",
            "        [-0.0994,  0.0530, -0.0857,  0.1089,  0.0158],\n",
            "        [-0.0980,  0.0483,  0.0436,  0.1622,  0.0257],\n",
            "        [-0.0258, -0.0769,  0.0135,  0.3799, -0.0029],\n",
            "        [-0.0249, -0.0820,  0.0180,  0.2152, -0.0265],\n",
            "        [ 0.0840, -0.1097,  0.0084,  0.1015, -0.1851]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network using sequential\n",
        "\n",
        "# Input as 20 features i.e. X\n",
        "# Ouput is 5 Taget variable / classes i.e. y\n",
        "\n",
        "sequential_model = nn.Sequential(\n",
        "    nn.Linear(20,64), # Input layer (20 -> 64)\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 5),\n",
        ")\n",
        "\n",
        "print(sequential_model)\n",
        "\n",
        "input_data = torch.randn(10, 20) # 10 rows, 20 is my feature size in each row\n",
        "print(input_data)\n",
        "print('='*40)\n",
        "output = sequential_model(input_data)   # pass data through model\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have just passed dataset through NN once and printed output."
      ],
      "metadata": {
        "id": "U6y5T2jFdOOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6lW3HIwO6n5",
        "outputId": "4ea389ff-8139-4ae2-c9d2-96fcad1a1679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights tensor([[ 0.1145, -0.1727,  0.0190,  ..., -0.2148, -0.0940, -0.1924],\n",
            "        [-0.2204,  0.1265,  0.0167,  ..., -0.1176, -0.0264, -0.0343],\n",
            "        [ 0.2199, -0.1449,  0.0154,  ..., -0.1216,  0.0190,  0.1438],\n",
            "        ...,\n",
            "        [ 0.1527, -0.1184,  0.1733,  ..., -0.1287,  0.0823,  0.0137],\n",
            "        [-0.0205,  0.1466,  0.0523,  ..., -0.2232,  0.0900,  0.0512],\n",
            "        [-0.0390, -0.1327, -0.1616,  ..., -0.0469, -0.2150, -0.2081]])\n",
            "Model bias tensor([-0.1180,  0.1718, -0.1929, -0.0837,  0.0298,  0.1231, -0.0505,  0.1697,\n",
            "        -0.2143, -0.0058,  0.1539,  0.0247, -0.1034,  0.0411, -0.2034, -0.0031,\n",
            "         0.0463,  0.1848,  0.0988,  0.0549, -0.1261, -0.1989, -0.0619, -0.1244,\n",
            "        -0.0317, -0.0805,  0.0688,  0.1641,  0.1848,  0.1699,  0.1156,  0.1284,\n",
            "         0.1026,  0.0458,  0.2203,  0.1285,  0.1728, -0.1079,  0.0267, -0.2059,\n",
            "         0.0299,  0.0319,  0.0068, -0.1288,  0.0695,  0.1392,  0.0008,  0.1115,\n",
            "         0.1476, -0.0194,  0.1476,  0.1157, -0.0771, -0.1931, -0.1179,  0.0534,\n",
            "        -0.1363,  0.0120, -0.0261, -0.2118,  0.2221,  0.2226,  0.2153,  0.1500])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model weights {sequential_model[0].weight.data}\")  # Print all weights\n",
        "print(f\"Model bias {sequential_model[0].bias.data}\")       # Print all bias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjfg57BbO6n6"
      },
      "source": [
        "# Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uG03ognO6n7",
        "outputId": "d85f7bd1-c80b-44fa-cf43-72cb183b32a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FunctionalModel(\n",
            "  (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "tensor([[-0.0366, -0.0435, -0.0063,  0.1008, -0.0495],\n",
            "        [-0.0318, -0.0608, -0.0030,  0.0106, -0.0833],\n",
            "        [ 0.0032, -0.0469, -0.0633,  0.1335,  0.0071],\n",
            "        [ 0.0801, -0.0230, -0.1440,  0.0350,  0.0261],\n",
            "        [ 0.0892, -0.0017, -0.0420,  0.0923, -0.1022],\n",
            "        [ 0.0695, -0.0452, -0.0458,  0.1448, -0.1315],\n",
            "        [ 0.0918,  0.0297, -0.0281, -0.0763, -0.1093],\n",
            "        [ 0.0217,  0.0766,  0.0268,  0.0911, -0.1068],\n",
            "        [ 0.0550, -0.0559, -0.0565,  0.0579, -0.0282],\n",
            "        [ 0.0969, -0.0128, -0.0287, -0.1143,  0.0251]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FunctionalModel(nn.Module):       # defined class for building model. nn.Module is inherited\n",
        "  def __init__(self):\n",
        "    super(FunctionalModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(20, 64)            # define required layers with inputs and outputs, define relu, dropout, batchnorm, etc required layers\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 5)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, X):                   # Define forward pass\n",
        "    x = self.relu(self.fc1(X))           # Pass input data through layer 1 and layer 1 through RELU\n",
        "    x = self.relu(self.fc2(x))           # Pass output of layer 1 through layer 2 and layer 2 through RELU\n",
        "    x = self.fc3(x)                      #\n",
        "    return x\n",
        "\n",
        "functional_model = FunctionalModel()     # Here we build model architecture\n",
        "\n",
        "print(functional_model)\n",
        "\n",
        "input_data = torch.randn(10, 20) # 10 rows, 20 is my feature size in each row\n",
        "#print(input_data)\n",
        "output = functional_model(input_data)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3cXYT_oK436"
      },
      "source": [
        "# Multi-Class Classification with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jXMd8PPhFWxv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QjwZKCwxIbCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcc1cde-02a1-4b5d-ccb7-a1a08337f212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Qa83_aHSLQ1S"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features (numerical data)\n",
        "y = iris.target  # Labels (3 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZqCpURX2LE64"
      },
      "outputs": [],
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KvdSiexrLIjX"
      },
      "outputs": [],
      "source": [
        "# Convert data to tensors\n",
        "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "y = torch.tensor(y, dtype=torch.long).to(device)  # Multi-class requires LongTensor for target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QabtPJeALJOI"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grjknIfBODqp",
        "outputId": "2c4cd020-e1e8-4a49-801e-3ff674bcec77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 4])\n",
            "============================================================\n",
            "tensor([[ 3.1100e-01, -5.9237e-01,  5.3541e-01,  8.7755e-04],\n",
            "        [-1.7367e-01,  1.7096e+00, -1.1697e+00, -1.1838e+00],\n",
            "        [ 2.2497e+00, -1.0528e+00,  1.7858e+00,  1.4488e+00],\n",
            "        [ 1.8983e-01, -3.6218e-01,  4.2173e-01,  3.9577e-01],\n",
            "        [ 1.1592e+00, -5.9237e-01,  5.9225e-01,  2.6414e-01],\n",
            "        [-5.3718e-01,  7.8881e-01, -1.2834e+00, -1.0522e+00],\n",
            "        [-2.9484e-01, -3.6218e-01, -8.9803e-02,  1.3251e-01],\n",
            "        [ 1.2803e+00,  9.8217e-02,  7.6276e-01,  1.4488e+00],\n",
            "        [ 4.3217e-01, -1.9736e+00,  4.2173e-01,  3.9577e-01],\n",
            "        [-5.2506e-02, -8.2257e-01,  8.0709e-02,  8.7755e-04],\n",
            "        [ 7.9567e-01,  3.2841e-01,  7.6276e-01,  1.0539e+00],\n",
            "        [-1.2642e+00, -1.3198e-01, -1.3402e+00, -1.4471e+00],\n",
            "        [-4.1601e-01,  1.0190e+00, -1.3971e+00, -1.3154e+00],\n",
            "        [-1.1430e+00,  9.8217e-02, -1.2834e+00, -1.4471e+00],\n",
            "        [-9.0068e-01,  1.7096e+00, -1.2834e+00, -1.1838e+00],\n",
            "        [ 5.5333e-01,  5.5861e-01,  5.3541e-01,  5.2741e-01],\n",
            "        [ 7.9567e-01, -1.3198e-01,  1.1606e+00,  1.3172e+00],\n",
            "        [-2.9484e-01, -1.2830e+00,  8.0709e-02, -1.3075e-01],\n",
            "        [-1.7367e-01, -5.9237e-01,  4.2173e-01,  1.3251e-01],\n",
            "        [ 6.7450e-01, -5.9237e-01,  1.0469e+00,  1.3172e+00],\n",
            "        [-1.3854e+00,  3.2841e-01, -1.2266e+00, -1.3154e+00],\n",
            "        [ 3.1100e-01, -1.3198e-01,  6.4908e-01,  7.9067e-01],\n",
            "        [-1.0218e+00,  7.8881e-01, -1.2266e+00, -1.0522e+00],\n",
            "        [ 6.7450e-01, -5.9237e-01,  1.0469e+00,  1.1856e+00],\n",
            "        [ 2.4920e+00,  1.7096e+00,  1.5016e+00,  1.0539e+00],\n",
            "        [ 1.0380e+00, -1.3198e-01,  8.1960e-01,  1.4488e+00],\n",
            "        [ 1.0380e+00, -1.2830e+00,  1.1606e+00,  7.9067e-01],\n",
            "        [ 1.1592e+00,  3.2841e-01,  1.2175e+00,  1.4488e+00],\n",
            "        [-1.2642e+00, -1.3198e-01, -1.3402e+00, -1.1838e+00],\n",
            "        [-1.2642e+00,  9.8217e-02, -1.2266e+00, -1.3154e+00]])\n",
            "tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
            "        2, 2, 2, 2, 0, 0])\n",
            "============================================================\n",
            "tensor([ 0.3110, -0.5924,  0.5354,  0.0009])\n",
            "tensor(1)\n"
          ]
        }
      ],
      "source": [
        "print(X_test.shape)\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(X_test[:,:])\n",
        "print(y_test[:])\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(X_test[0,:])\n",
        "print(y_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Lets build basic neural network**"
      ],
      "metadata": {
        "id": "t2baqWlNlqHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cE5-3fh3LLGI"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "class NeuralNetBasic(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNetBasic, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
        "        self.relu = nn.ReLU()  # Activation function\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  # Output layer for classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Model parameters\n",
        "input_size = X_train.shape[1]  # Number of features (4 for Iris)\n",
        "hidden_size = 16  # Arbitrary hidden layer size\n",
        "num_classes = 3  # Number of output classes (3 for Iris)\n",
        "\n",
        "# Instantiate the model\n",
        "model = NeuralNetBasic(input_size, hidden_size, num_classes).to(device)   # build model and send it to device (CPU/GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B. Lets build advanced neural network**\n",
        "\n",
        "(More number of neurons and with drop-out layers after hidden layer)\n",
        "\n",
        "As we are chosing cross entropy as loss function it automatically selects softmax as activation function in output layer\n",
        "\n",
        "(No need to define activation function in output layer)"
      ],
      "metadata": {
        "id": "anEEDewvl0PS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2huQU_DQLNwf"
      },
      "outputs": [],
      "source": [
        "# Neural network model with multiple layers\n",
        "class NeuralNetAdvance(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, num_classes):\n",
        "        super(NeuralNetAdvance, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)  # Second hidden layer\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)  # Third hidden layer\n",
        "        self.fc4 = nn.Linear(hidden_size3, num_classes)  # Output layer\n",
        "        self.relu = nn.ReLU()  # ReLU activation function\n",
        "        self.dropout1 = nn.Dropout(p=0.2)  # Dropout for regularization\n",
        "        self.dropout2 = nn.Dropout(p=0.5)  # Dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)  # Apply dropout to the first hidden layer\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)  # Apply dropout to the second hidden layer\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc4(x)  # Output layer (no activation, as CrossEntropyLoss applies softmax)\n",
        "        return x\n",
        "\n",
        "# Model parameters\n",
        "input_size = X_train.shape[1]  # Number of features (4 for Iris)\n",
        "hidden_size1 = 32  # First hidden layer size\n",
        "hidden_size2 = 64  # Second hidden layer size\n",
        "hidden_size3 = 32  # Third hidden layer size\n",
        "num_classes = 3  # Number of output classes (3 for Iris)\n",
        "\n",
        "# Instantiate the model\n",
        "model = NeuralNetAdvance(input_size, hidden_size1, hidden_size2, hidden_size3, num_classes).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sQ9W-PRGLa_g"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5fVaKTM-LeGo"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "num_epochs = 100  # Number of training iterations\n",
        "batch_size = 16  # Batch size for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2aFCPugjLfPI"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        # Forward pass\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOoRpw2UQYMZ"
      },
      "source": [
        "# How the Model Handles Batches?\n",
        "\n",
        "In the forward pass, PyTorch automatically handles multiple inputs (batches). This happens because the operations like matrix multiplication, addition, activation functions, etc., are all vectorized, meaning they are performed on the entire batch simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUBnIOZLiLo",
        "outputId": "ee7339a5-295a-4da2-b98f-da604a109ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.0625\n",
            "Epoch [20/100], Loss: 1.0004\n",
            "Epoch [30/100], Loss: 0.8940\n",
            "Epoch [40/100], Loss: 0.7656\n",
            "Epoch [50/100], Loss: 0.5939\n",
            "Epoch [60/100], Loss: 0.4593\n",
            "Epoch [70/100], Loss: 0.3865\n",
            "Epoch [80/100], Loss: 0.3333\n",
            "Epoch [90/100], Loss: 0.2856\n",
            "Epoch [100/100], Loss: 0.2343\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the training data\n",
        "train_model(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r21Nrmh-LjzQ",
        "outputId": "184321cf-61be-4f9f-9d1e-d70e0d698dee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetAdvance(\n",
              "  (fc1): Linear(in_features=4, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc4): Linear(in_features=32, out_features=3, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.eval()  # Set model to evaluation mode (no gradients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQWqbFJLlF5",
        "outputId": "13478772-9622-4bac-8dbb-db2ae679f573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 96.67%\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():  # No need to compute gradients during testing\n",
        "    test_outputs = model(X_test)\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Get the class with highest probability\n",
        "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
        "    print(f'Accuracy on the test set: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfccrnKLmpY",
        "outputId": "d8fb0e80-d67c-480a-c98d-7a2bff12ab50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9007,  1.0190, -1.3402, -1.3154],\n",
            "        [ 0.7957, -0.1320,  0.9901,  0.7907]])\n"
          ]
        }
      ],
      "source": [
        "# Example of prediction on new data\n",
        "new_data = torch.tensor([[5.1, 3.5, 1.4, 0.2], [6.5, 3.0, 5.5, 1.8]], dtype=torch.float32).to(device)\n",
        "new_data = torch.tensor(scaler.transform(new_data.cpu()), dtype=torch.float32).to(device)\n",
        "print(new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_JbVs28PzaK"
      },
      "source": [
        "* scaler.transform(new_data.cpu()) scales the data and returns a NumPy array.\n",
        "* torch.tensor(...) converts the NumPy array back to a PyTorch tensor.\n",
        "* .to(device) moves the tensor to the appropriate device (CPU or GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P008zXP6LpNo",
        "outputId": "7b337729-773c-4857-8493-23887959b82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes for new data: [0 2]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    predictions = model(new_data)\n",
        "    _, predicted_classes = torch.max(predictions, 1)\n",
        "    print(\"Predicted classes for new data:\", predicted_classes.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq1XxuS4Nx9i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}