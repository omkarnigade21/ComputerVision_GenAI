{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3N6S70vjM68"
      },
      "source": [
        "# Create a Custom Dataset Class for Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jXMd8PPhFWxv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yyiu3c_ljM7D"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):  # accepts input as directory/folder where all images are saved in respective class named folders\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform   # Any image transformation operation\n",
        "        self.image_paths = []  # Store image file paths\n",
        "        self.labels = []  # Store image labels\n",
        "\n",
        "        # Load all image paths and their corresponding labels (class folder names)\n",
        "        for label, class_dir in enumerate(os.listdir(image_dir)):  # Each folder is a class (folder name = class_name)\n",
        "            class_path = os.path.join(image_dir, class_dir)    # Path of folder of each class\n",
        "            for img_name in os.listdir(class_path):                  # iterate through each class_name folder\n",
        "                self.image_paths.append(os.path.join(class_path, img_name))   # Append path of each image in class_name folder into list\n",
        "                self.labels.append(label)                                     # Append respective class of image in this list ie folder name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)  # Returns the total number of images\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]      # get image path\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # Load image and convert to RGB\n",
        "        label = self.labels[idx]               # get respective lebel\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)   # apply mentioned transformation on image\n",
        "\n",
        "        return image, label                 # lists contains images path and respective class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_hGhPRyVjM7D"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "collapsed": true,
        "id": "3kpEEHMXjM7E",
        "outputId": "df71f2f6-ccae-4fd6-9fd5-64f320f7bce1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a91833f67298>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-4f0c30444992>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, transform)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Load all image paths and their corresponding labels (class folder names)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Each folder is a class (folder name = class_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Path of folder of each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                  \u001b[0;31m# iterate through each class_name folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/train'"
          ]
        }
      ],
      "source": [
        "# Paths to the image datasets\n",
        "train_image_dir = 'path/to/train'\n",
        "val_image_dir = 'path/to/val'\n",
        "test_image_dir = 'path/to/test'\n",
        "\n",
        "# Create datasets\n",
        "train_image_dataset = ImageDataset(image_dir=train_image_dir, transform=transform)\n",
        "val_image_dataset = ImageDataset(image_dir=val_image_dir, transform=transform)\n",
        "test_image_dataset = ImageDataset(image_dir=test_image_dir, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_image_loader = DataLoader(dataset=train_image_dataset, batch_size=32, shuffle=True)\n",
        "val_image_loader = DataLoader(dataset=val_image_dataset, batch_size=32, shuffle=False)\n",
        "test_image_loader = DataLoader(dataset=test_image_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Example: Iterating through batches of the train_image_loader\n",
        "for images, labels in train_image_loader:\n",
        "    print(images.shape, labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMXV5fRQjM7E",
        "outputId": "7988a5f0-85ad-4a3b-e0ec-fa2bd89326ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['README.md', 'anscombe.json', 'mnist_train_small.csv', 'mnist_test.csv', 'california_housing_test.csv', 'california_housing_train.csv']\n",
            "0 README.md\n",
            "/content/sample_data/README.md\n",
            "1 anscombe.json\n",
            "/content/sample_data/anscombe.json\n",
            "2 mnist_train_small.csv\n",
            "/content/sample_data/mnist_train_small.csv\n",
            "3 mnist_test.csv\n",
            "/content/sample_data/mnist_test.csv\n",
            "4 california_housing_test.csv\n",
            "/content/sample_data/california_housing_test.csv\n",
            "5 california_housing_train.csv\n",
            "/content/sample_data/california_housing_train.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(os.listdir(\"/content/sample_data\"))\n",
        "\n",
        "for idx, file_name in enumerate(os.listdir(\"/content/sample_data\")):\n",
        "  print(idx, file_name)\n",
        "  print(os.path.join(\"/content/sample_data\", file_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}